<!DOCTYPE html>
<html lang="en">
<head>
          <title>Lukas Woodtli</title>
        <meta charset="utf-8" />



    <meta name="tags" content="Computer Science" />
    <meta name="tags" content="OS" />

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="http://lukaswoodtli.github.io/">Lukas Woodtli <strong></strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li><a href="/index.html">Home</a></li>
            <li><a href="/pages/resume.html">Resume</a></li>
            <li><a href="[(u'Hard Skills', u'/pages/skills.html'), (u'Courses', u'/pages/courses.html'), (u'Books', u'/pages/books.html'), (u'Projects', u'/pages/projects.html')]">Skills</a></li>
            <li><a href="[(u'Blog Index', u'/pages/blog.html'), (u'Categories', u'/categories.html'), (u'Tags', u'/tags.html'), (u'Chronological', u'/archives.html')]">Blog</a></li>
            <li><a href="/pages/contact.html">Contact</a></li>
            <li><a href="http://lukaswoodtli.github.io/pages/blog.html">Blog</a></li>
            <li><a href="http://lukaswoodtli.github.io/pages/books.html">Books</a></li>
            <li><a href="http://lukaswoodtli.github.io/pages/contact.html">Contact</a></li>
            <li><a href="http://lukaswoodtli.github.io/pages/courses.html">Courses</a></li>
            <li><a href="http://lukaswoodtli.github.io/">Welcome to my Site</a></li>
            <li><a href="http://lukaswoodtli.github.io/pages/projects.html">Projects</a></li>
            <li><a href="http://lukaswoodtli.github.io/pages/note_to_recruiters_and_headhunters.html">Note to Recruiters and Headhunters</a></li>
            <li><a href="http://lukaswoodtli.github.io/pages/resume.html">Resume</a></li>
            <li><a href="http://lukaswoodtli.github.io/pages/skills.html">Skills</a></li>
        </ul></nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="http://lukaswoodtli.github.io/modern_oss.html" rel="bookmark"
         title="Permalink to Modern OS's">Modern OS's</a></h2>
 
  </header>
  <footer class="post-info">
    <abbr class="published" title="2015-04-01T00:00:00+02:00">
      Wed 01 April 2015
    </abbr>
    <abbr class="modified" title="2017-01-12T00:00:00+01:00">
      Thu 12 January 2017
    </abbr>
    <address class="vcard author">
      By           <a class="url fn" href="http://lukaswoodtli.github.io/author/lukas_woodtli.html">Lukas Woodtli</a>
    </address>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p>This page collects some notes about different Operating System approaches.</p>
<p>Most of the information gathered here is from the course <a href="https://www.udacity.com/course/ud189">Advanced Operating Systems</a>.</p>
<p>Some information is from <a href="http://en.wikipedia.org/wiki/Operating_system" title="Wikipedia">Operating System</a>. And other Wikipedia pages.</p>
<p>The book <em>Modern Operating Systems</em> by Andrew S. Tanenbaum is also a very good resource I'm using for learning about Operating Systems.
5</p>
<p>[TOC]</p>
<h1>Overview of Kernels</h1>
<blockquote>
<p>This overview Table is still work in progress!</p>
</blockquote>
<table class="table table-hover table-striped">
<thead>
<tr>
<th>Kernel</th>
<th>Type</th>
<th>Programming Language</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://en.wikipedia.org/wiki/SPIN_(operating_system)">SPIN</a></td>
<td>Microkernel (Mach-like)</td>
<td>Modula-3</td>
<td>Special approach.</td>
</tr>
<tr>
<td>Linux</td>
<td>Monolithic (modular)</td>
<td>C, Assembly</td>
<td>Loadable kernel modules allow loading extensions (drivers) at runtime.</td>
</tr>
<tr>
<td>XNU</td>
<td>Hybrid</td>
<td>C, C++</td>
<td>Kernel of OS X. Mach-3.0 and FreeBSD combined.</td>
</tr>
<tr>
<td>BSD</td>
<td>Monolithic</td>
<td>C</td>
<td>FreeBSD, OpenBSD, NetBSD...</td>
</tr>
<tr>
<td>Mach</td>
<td>Microkernel</td>
<td>C?</td>
<td>One of the earlyest mikrokernel. Not all mach versions are mikrokernels.</td>
</tr>
<tr>
<td>Windows</td>
<td>Hybrid</td>
<td>C, C++, Assembly</td>
<td>Win NT: Hybrid, Win 9x and earlyer: Mololithic.</td>
</tr>
<tr>
<td>FreeRTOS</td>
<td>Microkernel (RTOS)</td>
<td>C, Assembly</td>
<td>Real Time OS. Mainly for embedded systems.</td>
</tr>
<tr>
<td>UNIX</td>
<td>Monolithic</td>
<td>C, Assembly</td>
<td>Original: AT&amp;T Unix.</td>
</tr>
<tr>
<td>L3</td>
<td>Microkernel</td>
<td>ELAN</td>
<td>Predecessor of L4.</td>
</tr>
<tr>
<td>Barrelfish</td>
<td>"Multikernel"</td>
<td>C</td>
<td>Special aproach.</td>
</tr>
<tr>
<td>Mac OS 9</td>
<td>Microkernel (Nanokernel)</td>
<td>?</td>
<td>Legacy</td>
</tr>
<tr>
<td>QNX</td>
<td>Microkernel (RTOS)</td>
<td>?</td>
<td>Unix-Like (POSIX), Qt supported.</td>
</tr>
<tr>
<td>VxWorks</td>
<td>Monolithic (RTOS)</td>
<td>?</td>
<td></td>
</tr>
<tr>
<td><a href="https://en.m.wikipedia.org/wiki/Spring_(operating_system)">Spring</a></td>
<td>Microkernel</td>
<td>independent (CORBA IDL)</td>
<td>Solaris emulation, OOP design, doors ...</td>
</tr>
</tbody>
</table>
<h1>Other OS's:</h1>
<ul>
<li><a href="https://en.m.wikipedia.org/wiki/Nucleus_RTOS">Nucleus RTOS</a></li>
<li><a href="https://en.m.wikipedia.org/wiki/ChorusOS">ChorusOS</a></li>
</ul>
<h1>Sharing Resources</h1>
<p>One of the most important task of an OS is to share (hardware) resources. There are two posibilities how resources can be shared.</p>
<ol>
<li>time sharing: i.e CPU, Printer</li>
<li>space sharing: i.e RAM, Hard Disc</li>
</ol>
<h1>Exokernel</h1>
<p>Allocating resources to library OS's:</p>
<ul>
<li>space (memory)</li>
<li>time (CPU)</li>
</ul>
<p>Library OS's can 'download' code into the kernel. A security management mechanism checks if it is allowed by th library OS.</p>
<h2>Memory (TLB)</h2>
<p>TLB: Translation Lookaside Buffer.
Software-TLB is snapshot for the TLB for switching the library OS's.</p>
<h2>CPU-Scheduling</h2>
<ul>
<li>Linear vector of "time slots"</li>
<li>Each library-OS marks the time slots for own use</li>
<li>If OS takes more time than allowed in a time slot it gets less time in the next time slot (penalty)</li>
<li>Strand as abstraction of threads</li>
</ul>
<h2>Revoction of Resources</h2>
<ul>
<li>Exokernel tells the library OS which resources are revoked (repossesion vector)</li>
</ul>
<h1>L3</h1>
<h2>L3 strikes against microkernel</h2>
<ul>
<li>Kernel-User switches (boarder crossing cost)</li>
<li>Address space switches (Protected Procedures Calls for Cross Protection domain calls)</li>
<li>Thread switches + IPC (Kernel mediation for PPC)</li>
<li>Memory effects (locality loss)</li>
</ul>
<h2>Thesis of L3 for OS structuring</h2>
<ul>
<li>Minimal abstractions in microkernel</li>
<li>Microkernels are processor specific in implementation =&gt; non-portable</li>
<li>Right set of microkernel abstractions and processor-specific implementation =&gt; efficient processor independent abstractions at higher levels</li>
</ul>
<p>L3 is faster than Mach (Microkernel).</p>
<h1>Virtualization</h1>
<p>Hypervisor: Operation system of operation systems (VMM: Virtal Machine Monitor).</p>
<h2>Native Hypervisor (bare metal)</h2>
<p>Hypervisor runs directly on hardware.
Guest OS's running inside the hypervisor.</p>
<h2>Hosted Hypervisors</h2>
<p>Run on top of a Host OS (as an application process).
Guest OS's running inside the hypervisor.</p>
<ul>
<li>VMWare Workstation</li>
<li>VirtualBox</li>
</ul>
<h2>Full virtualization</h2>
<ul>
<li>Guest OS's are not touched (unchanged binaries)</li>
<li>They are running as user process in host OS</li>
<li>Privileged instructios in guest OS's trigger trap in hypervisor (trap and emulate)</li>
<li>i.e. VMWare</li>
</ul>
<h2>Para Virtualization</h2>
<ul>
<li>Guest OS is modified to run on an an hypervisor</li>
<li>A very small percentage of the guest OS code needs to be changed</li>
<li>i.e. Xen</li>
</ul>
<h2>Overview</h2>
<p>Virtualize hardware:</p>
<ul>
<li>memory hierarchy</li>
<li>CPU</li>
<li>Devices</li>
</ul>
<h1>Memory Virtualization</h1>
<h2>Not virtualized:</h2>
<p>Page Table (PT) maps Virtual Page Numbers (VPN) of processes to Physical Page Number (PPN).</p>
<h2>Virtualized:</h2>
<p>Guest OS translates Virtual Page Number (VPN) to Physical Page Number (PPN) with Page Table (PT). Hypervisor then translates Physical Page Number (PPN) to Machine Page Number (MPN) with Shadow Page Table (S-PT).</p>
<h1>CPU Virtualization</h1>
<p>Events that happen in a task of the Guest OS need to be delivered to the Guest OS by the Hypervisor.</p>
<p>An event can be:</p>
<ul>
<li>External Interrupt (HW Interrupt)</li>
<li>Exception (HW- and SW-Exception)</li>
<li>Page Fault</li>
<li>Syscall</li>
</ul>
<p>The occured events are delivered to the Guest OS wrapped in a SW-Interrupt by the Hypervisor.</p>
<p>Communication from the Guest OS to the CPU hapens generally through traps. So the hypervisor can
handle it. In para-virtualized environment the Hypervisor can provide an API for the Guest OS instead
of using traps.</p>
<ul>
<li>Full virtualization: "trap and emulate"</li>
<li>Para virtualization: more opportunity for innovation</li>
</ul>
<h2>Control Transfer</h2>
<h3>Full virtualization</h3>
<ul>
<li>implicit (traps) guest → hypervisor</li>
<li>software interrupts (events) hypervisor → guest</li>
</ul>
<h3>Para virtualization</h3>
<ul>
<li>explicit (hypercalls) guest → hypervisor</li>
<li>software interrupts (events) hypervisor → guest</li>
</ul>
<blockquote>
<p>Guest has control via hypercalls on when event notifications
  need to be delivered.</p>
</blockquote>
<h2>Data Transfer</h2>
<h3>Full virtualization</h3>
<ul>
<li>implicit</li>
</ul>
<h3>Para virtualization (e.g. Xen)</h3>
<ul>
<li>explicit ⇒ opportunity to innovate</li>
</ul>
<h4>Xen I/O-Rings</h4>
<p>Xen uses a ring buffer for data transfer with producer-consumer pattern.
There are 4 pointer to the buffer.</p>
<ol>
<li>Request producer (shared, updated by guest)</li>
<li>Request consumer (private to Xen)</li>
<li>Response producer (shared, updated by guest)</li>
<li>Response consumer (private to guest)</li>
</ol>
<h1>Memory Models</h1>
<ul>
<li>Memory Consistency: What is the Model presented to the Programmer?</li>
<li>Cache Coherence: How is the System implementing the Model in presence of private caches?</li>
</ul>
<h2>Sequential Consistency (Memory Model)</h2>
<p>Access to a shared memory location is performed in sequence by the processors. The accesses can be
interwoven.</p>
<h2>Cache Coherence</h2>
<h3>Non cache coherent shared address space multi processor (NCC shared memory multi processor)</h3>
<p>System only gives access to shared address space. System Software maintains chaching.</p>
<ul>
<li>Shared address space available for all processors</li>
<li>Private caches</li>
</ul>
<blockquote>
<p>If you modify data it's a problem of the system software to make sure the caches are coherent!</p>
</blockquote>
<h3>CC shared memory multi processor</h3>
<ul>
<li>Hardware provides shared address space</li>
<li>Maintains cache coherence in hardware</li>
</ul>
<h4>Write-Invalidate</h4>
<p>Hardware ensures that written memory location is invalidated in all caches.</p>
<h4>Write-Update</h4>
<p>Hardware ensure that modified memory location is updated in all caches.</p>
<blockquote>
<p>"Shared memory machines scale well when you don't share memory.", Chuck Thacker</p>
</blockquote>
<h1>Synchronization</h1>
<h2>Synchronization Primitives</h2>
<ul>
<li>Mutex Locks (single exclusive access to resource)</li>
<li>Shared Lock (Multiple reader to one resource)</li>
<li>Barriers (Synchronize threads, wait for other threads till all completed their work)</li>
</ul>
<h2>Atomic Instruction</h2>
<p>During the execution of an instruction the processor can not be interrupted.</p>
<p>Aquiring a lock needs to be atomic.</p>
<h3>Read-Modify-Write (RMW)</h3>
<p>Different aproaches:</p>
<ul>
<li>Test-and-Set (T+S): Reads a memory location. Then returns the actual value and sets it to 1 atomically.</li>
<li>Fetch-and-Inc: Reads a memory location. Then returns the actual value and increments it atomically.</li>
<li>Fetch-and-<span class="math">\(\Phi\)</span>: Generally with any given function (<span class="math">\(\Phi\)</span>) after fetching and returning the actual value.</li>
</ul>
<h3>Scalability issues with Synchronitation</h3>
<ul>
<li>Latency: Latency is the time that a thread needs to acquire a lock.</li>
<li>Waiting time: The time that a thread needs to wait to get the lock. This time is in the hands of the application developers and not of the OS developers.</li>
<li>Contention: If a lock is released and several threads are waiting for it. How long does it take until a thread is chosen from the waiting threads.</li>
</ul>
<h2>Spinlock</h2>
<h3>Naive Spinlock (Spin on T+S)</h3>
<p>A thread or processor waiting for a lock loops (spins) without doing any useful work.</p>
<div class="highlight"><pre>LOCK(L):
    WHILE(T+S(L) == locked);
</pre></div>
<p>Problems with this naive spinlock implementation:</p>
<ul>
<li>Too much contention: Every processor tries to access lock.</li>
<li>Does not exploit caches: Private caches in processor can't contain lock variable (T+S needs to be atomic. That's not possible with cached variables).</li>
<li>Disrupts useful work: After releasing a lock a processor usually wants to do some work. But other processors need resources for trying to acquire the lock.</li>
</ul>
<h3>Caching Spinlock (Spin on read)</h3>
<p>Waiting processors spin on cached copy of <code>L</code>. So there is no communication to memory. The cached copy
of <code>L</code> is updated by the cache coherence mechanism of the system.</p>
<div class="highlight"><pre>LOCK(L):
    WHILE(L == locked); // Spinning on cached var. Reading L is atomic.
        IF(T+S(L) == locked) // Read L from memory (not cache).
            go back; // If it fails start spinning on cached L again.
</pre></div>
<ul>
<li>Less traffic on bus.</li>
<li>Disruptive.</li>
</ul>
<h3>Spinlock with Delay</h3>
<p>If a lock is released every process waits for a given time before trying to aquire the lock.</p>
<h4>Delay after lock release</h4>
<div class="highlight"><pre>WHILE((L == locked) or
      (T+S(L) == locked))
{
    WHILE(L == locked);
    delay(d[Pi]); // when I get the lock I wait a while
}
</pre></div>
<p>The delay time is dependent on the processor.</p>
<h4>Delay with exponential backoff</h4>
<div class="highlight"><pre>WHILE(T+S(L) == locked) // not using chaching at all
{
    delay(d); // d is small at first
    d = d * 2;
}
</pre></div>
<p>Every time when the lock is checked and not free the processor waits a longer time before trying again.
T+S can be used because we wait before trying to quire the lock again. This reduces the contention.
This algorithm works also on architecture without chaches (or cache coherent system in HW).</p>
<h3>Ticket Lock</h3>
<p>The process that tries to acquire a lock gets a ticket.
When the lock is released the process is notified.</p>
<p>This adds fairness to the locking algorithm.</p>
<p>But it causes contention.</p>
<h3>Summary</h3>
<ul>
<li>Spin on T+S, Spin on read and Spinlock with Delay are not fair</li>
<li>Ticket Lock is fair but noisy (contention)</li>
</ul>
<h2>Queuing Lock</h2>
<h3>Array-based queuing Lock (Anderson Lock)</h3>
<p>For each lock there is an array with flags. The size of the
array is equal to the number of processors.</p>
<p>Flags:</p>
<ul>
<li>has-lock (<strong>hl</strong>)</li>
<li>must-wait (<strong>mw</strong>)</li>
</ul>
<p><img alt="The flag array structure" class="img-responsive" src="/images/array_based_queuing_lock.png"/></p>
<p>Only one slot can be marked as <strong>hl</strong>.</p>
<p>The slots are not statically associated with a particular processor.</p>
<div class="highlight"><pre>LOCK(L):
   myPlace = fetch_and_inc(queuelast);
   WHILE(flags[myPlace mod N] == mw);

UNLOCK(L):
    flags[current mod N] = mw; // release lock for feature use
    flags[(current+1) mod N] = hl; // next processor in queue gets lock
</pre></div>
<ul>
<li>Only one atomic operation needed per critical section</li>
<li>Fairness: first-come, first-served</li>
<li>But needs a lot of space. For each lock there is one array with the size of number of processors</li>
</ul>
<h3>Link Based queuing Lock</h3>
<p>The Locks are stored in a linked list.</p>
<p>Synchronization for adding and removing clients to a lock.</p>
<p>Published by <a href="http://www.cs.rice.edu/~johnmc/papers/tocs91.pdf">John M. Mellor-Crummey and Michael L. Scott (MCS)</a></p>
<h1>Parallel Architectures</h1>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Symmetric_multiprocessing">Symmetric multiprocessing (SMP)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Non-Uniform_Memory_Access">Non-uniform memory access (NUMA)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cache_coherence">Cache coherence</a></li>
<li><a href="https://en.wikipedia.org/wiki/Computer_cluster">Computer cluster</a></li>
</ul>
<p>OS:</p>
<h1>Spring</h1>
<p><a href="https://en.m.wikipedia.org/wiki/Spring_(operating_system)">Wikipedia:Spring (operating system)</a></p>
<p><a href="https://www.cs.fsu.edu/~awang/courses/cop5611_s2004/spring.pdf">An Overview of the Spring System</a></p>
<ul>
<li>Indepentant of programming language (CORBA IDL)</li>
<li>OOP</li>
<li>Microkernel</li>
<li>Spring Nucleus: secure objects with high speed object invocation between address spaces and networked machines</li>
<li>Object managers:<ul>
<li>e.g. file system: file objects</li>
<li>running in non-kernel mode</li>
<li>like server</li>
</ul>
</li>
<li>IDL (CORBA) Generate:<ol>
<li>Interface (e.g. header file)</li>
<li>Client side stub code: get access to object implemented in other address space or machine</li>
<li>Server side stub code: used by object manager to translate remote object invocations into the run-time environment of object implementation</li>
</ol>
</li>
<li>Serverless objects<ul>
<li>entire state of object always in clients address space</li>
<li>passing to other address space: copy entire state</li>
</ul>
</li>
<li>Subcontracts<ul>
<li>plugging different kinds of object runtimes</li>
<li>control how<ul>
<li>object invocation is implemented</li>
<li>object references are transmitted between address spaces</li>
<li>object references are released</li>
<li>...</li>
</ul>
</li>
<li>Subcontracts<ul>
<li>Singleton</li>
<li>Replication</li>
<li>Cheap objects</li>
<li>Caching</li>
<li>Crash recovery</li>
<li>...</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>Overall System Structure</h2>
<ul>
<li>Microkernel<ul>
<li>Processes, IPC and Memory management part of kernel (Liedtke)</li>
</ul>
</li>
<li>Kernel mode<ul>
<li>Nucleus: processes and IPC<ul>
<li>Entered by trap mechanism</li>
</ul>
</li>
<li>Virtual Memory Manager<ul>
<li>page faults</li>
<li>external pagers (looks like any other object server)</li>
<li>...</li>
</ul>
</li>
</ul>
</li>
<li>All other system services implemented as user-level servers<ul>
<li>naming</li>
<li>paging</li>
<li>network IO</li>
<li>file systems</li>
<li>keyboard management</li>
<li>...</li>
</ul>
</li>
<li>inherently distributed: all services and objects available on one node are also a available on other nodes in the distributed system</li>
</ul>
<h2>Nucleus</h2>
<ul>
<li>Three basic abstractions: domains, threads and doors</li>
<li>No memory management</li>
<li>Domains<ul>
<li>analogous to processes in Unix or tasks in Mach</li>
<li>address space for applications</li>
<li>resources: threads, doors, ...</li>
</ul>
</li>
<li>Threads<ul>
<li>execute within domains</li>
</ul>
</li>
<li>Doors<ul>
<li>Cross domain calls</li>
<li>OOP calls between domains</li>
<li>entry points to domains</li>
<li>represented by a PC and a unique value (nominated by domain)</li>
<li>unique value used by object server to identify state of object</li>
<li>unique value might be a C++ pointer</li>
</ul>
</li>
</ul>
<h3>Doors</h3>
<ul>
<li>pieces of protected nucleus state</li>
<li>each domain has a table with doors it has access to</li>
<li>refers to doors using <em>door identifiers</em></li>
<li>same door may be referenced by several different door identifiers in different domains</li>
<li>possesion of door: right to send invocation request to door</li>
<li>valid door can be obtained with consent of<ul>
<li>target domain</li>
<li>someone who already has door identifier to that door</li>
</ul>
</li>
<li>doors can be passed as arguments or be returned as values from functions</li>
</ul>
<h3>Object invocations via Doors</h3>
<ul>
<li>cross-address-space invocation</li>
<li>Algorithm<ol>
<li>nucleus allocates server thread in target address space</li>
<li>nucleus transfers control to that thread, passing information about door and the arguments of the invoked method</li>
<li>when the called thread returns:<ul>
<li>deactivation of the thread</li>
<li>activation of caller thread</li>
<li>passing return data</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2>Network Proxies</h2>
<p>rovide object invocation across network
- connect nuclei of different machines transparently
- proxies are normal user-mode domains (no special support from nucleus)
- client and server need not to be aware that proxies exist: normal door invocation</p>
<h2>Security model</h2>
<ul>
<li>secure access to objects</li>
<li>two basic security mechanisms:<ul>
<li>Access Control Lists</li>
<li>software capabilities</li>
</ul>
</li>
<li>invocations are controlled by nucleus doors and front objects</li>
</ul>
<h2>Virtual Memory</h2>
<ul>
<li>demand-paged virtual memory system</li>
<li>per machine virtual memory manager (VMM) handles local memory:<ul>
<li>mapping</li>
<li>sharing</li>
<li>protection</li>
<li>transfer</li>
<li>caching</li>
</ul>
</li>
<li>depends on <em>external pagers</em> for accessing store and maintaining inter-machine coherency</li>
<li><em>Address Space</em> and <em>Memory</em> objects used by clients</li>
<li>Adress Space:<ul>
<li>virtual address space of domain</li>
<li>implemented by VMM</li>
</ul>
</li>
<li>Memory<ul>
<li>abstraction of memory that can be mapped to address space</li>
<li>can be a file</li>
<li>operations to set and query length and bind</li>
<li>no read/write or page-in/out operations</li>
</ul>
</li>
<li>Separating memory from interface for paging<ul>
<li>useful for implementing filesystem</li>
<li>Memory Object server can be on different machine than the Pager Object server</li>
</ul>
</li>
</ul>
<h3>Cache and Pager Objects</h3>
<ul>
<li>two-way connection between the VMMs and external pagers</li>
<li>cache must be coherent between more than one VMM</li>
<li>VMM obtains data by invoking pager object implemented by external pager</li>
<li>external pager performs coherency actions by invoking cache object implemented by a VMM</li>
<li>the coherency protocol is not specified by the architecture: external pagers can implement  any coherency protocol</li>
</ul>
<h2>File System</h2>
<ul>
<li>file objects implemented by fileserver</li>
<li>file objects may be memory mapped</li>
<li>access to files on local disks or over the network</li>
<li>Spring security and naming architectures to provide access control and directory services</li>
<li>Spring file system typically consists of several layered file servers</li>
</ul>
<h2>Spring Naming</h2>
<ul>
<li>Naming for:<ul>
<li>users</li>
<li>files</li>
<li>printers</li>
<li>machines</li>
<li>services</li>
<li>...</li>
</ul>
</li>
<li>uniform name service</li>
<li>any object can be bound to any name</li>
<li>Object can be:<ul>
<li>local to a process</li>
<li>local to a machine</li>
<li>resident on the network</li>
<li>transient or persistent</li>
<li>standard system object</li>
<li>process environment object</li>
<li>user specific object</li>
</ul>
</li>
<li>new name spaces  can be compose of different name spaces</li>
<li>name service allows objects to be associated with a name in a context</li>
<li>objects need not be bound to a name</li>
<li>naming graph (name space):<ul>
<li>a directed graph</li>
<li>nodes with outgoing edges are contexts</li>
</ul>
</li>
<li>naming provide persistence</li>
<li>access control and authentication</li>
</ul>
<h2>UNIX Emulation</h2>
<ul>
<li>Spring can run Solaris binaries</li>
<li>implemented by user-level code</li>
<li>contains no UNIX code</li>
<li>two components:<ul>
<li>a shared library (libue.so), dynamically linked with each Solaris binary</li>
<li>a set of UNIX-specific services</li>
</ul>
</li>
</ul>
<h1>Barrelfish</h1>
<ul>
<li>Multikernel</li>
<li>OS as distributed system of functional units (network of independent cores)</li>
<li>communication via explicit messages (message passing)</li>
<li>Design principles<ol>
<li>Make all inter-core communication explicit (message passing)</li>
<li>Make OS structure HW-neutral</li>
<li>View state as replicated instead of shared</li>
</ol>
</li>
<li>Single computer as networked system</li>
<li>RPC<ul>
<li>latency is lower than shared memory access</li>
<li>asynchronous or pipelined RPC: client processors can avoid stalling on cache misses</li>
</ul>
</li>
<li>Asynchronous messaging: event-driven programming</li>
<li>pitfalls with shared data structures in scalable progams:<ul>
<li>correctness</li>
<li>performance</li>
<li>lock granularity</li>
<li>field layout in structures (alignment ...)</li>
</ul>
</li>
<li>applications can share memory across cores, but OS design does not reky on shared memory</li>
<li>networking optimizations for message passing:<ul>
<li>pipelining: a number of requests in flight at once</li>
<li>batching: sending or processing a number of messages together</li>
</ul>
</li>
<li>Multikernel separates OS structure from hardware</li>
<li>Replication of state is a useful framework for:<ul>
<li>changes to the running cores</li>
<li>hotplugging processors</li>
<li>shutting down subsystems to save power</li>
</ul>
</li>
<li>Replication:<ul>
<li>Benefit of performance and availability</li>
<li>at cost of ensuring replica consistency</li>
</ul>
</li>
<li>porting application to Barrelfish are straightforward<ul>
<li>standard C and mate library</li>
<li>Virtual Memory Management</li>
<li>subset of POSIX threads and file I/O APIs</li>
</ul>
</li>
</ul>
<h2>System Structure</h2>
<ul>
<li>multiple independent OS instances</li>
<li>communication via explicit messages</li>
<li>each OS instance per core<ul>
<li>privileged mode CPU driver</li>
<li>user mode monitor process</li>
</ul>
</li>
<li>CPU driver local to core</li>
<li>monitor<ul>
<li>performes inter-core coordination</li>
<li>coordinate system-wide state</li>
<li>handling message-oriented inter-core communication</li>
<li>mostly processor-agnostic</li>
</ul>
</li>
<li>monitor and CPU driver encapsulate: scheduling, communication and resource allocation</li>
<li>device drivers and system services (network stack, memory allocators ...) run in user mode</li>
<li>device interrupts are routed in hardware to the appropriate core</li>
<li>CPU driver<ul>
<li>enfonces protection</li>
<li>performs authorization</li>
<li>timeslices processes</li>
<li>mediates access to core and associated hardware (MMU, APIC ...)</li>
<li>completely event-driven and non-preemptable (single threaded)</li>
<li>processes events: traps from user processes, interrupts from devices to other cores</li>
</ul>
</li>
<li>Process structure<ul>
<li>collection of dispatcher objects (cores)</li>
<li>dispatchers scheduled by local CPU driver</li>
</ul>
</li>
<li>Inter-core communication<ul>
<li>user-level RPC (URPC):<ul>
<li>marschaling code generated with stub compiler</li>
<li>name service to locate services</li>
<li>channels established between services (setup performed by monitors)</li>
<li>no shared memory other than URPC channel and packet payload</li>
</ul>
</li>
</ul>
</li>
<li>cross-core thread management is performed in user-space<ul>
<li>thread schedulers exchange messages to create and unblock threads and migrate threads between cores</li>
<li>POSIX like threads</li>
</ul>
</li>
</ul>
<h2>Memory Management</h2>
<ul>
<li>global set of resources</li>
<li>user-level app and services services use shared memory across multiple cores</li>
<li>capability system (<a href="https://sel4.systems/"> seL4</a>)</li>
<li>virtual memory management (allocation/manipulation of page tables...) entirely in user-space</li>
<li>capability code is complex</li>
</ul>
<h2>Knowledge and Policy Engine</h2>
<ul>
<li>Maintaining  knowledge of hardware in <a href="http://wiki.barrelfish.org/SystemKnowledgeBase">'system knowledge base'</a></li>
<li>subset of first-order logic: <a href="http://eclipseclp.org/">The ECLiPSe Constraint Programming System</a></li>
<li>declarative approach</li>
<li>hardware discovery</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
  </div><!-- /.entry-content -->
</section>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>